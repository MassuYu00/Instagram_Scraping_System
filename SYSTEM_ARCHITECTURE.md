# 📱 Instagram Scraping System - システム仕様書

> **最終更新**: 2026-02-08
> **バージョン**: 2.0 (Hashtag Scraper対応)

このプロジェクトは、**海外在住の日本人（ワーホリ、留学生、駐在員）向け**に、Instagramから**求人・住居・イベント情報**を自動収集・分類・整理するシステムです。

---

## 🎯 プロジェクト目的

ワーキングホリデーや語学留学などで海外を訪れる日本人は、家探しや仕事探しなどの情報を共有し合う掲示板を使う傾向があります。このシステムは、Instagramに散在する有用な情報を自動的に収集・分類し、ユーザーに提供することを目的としています。

### ターゲットユーザー
- 🇨🇦 カナダ（トロント）へのワーホリ
- 🇹🇭 タイ（バンコク）への駐在員・現地採用
- 🇵🇭 フィリピン（セブ）への語学留学生
- 🇬🇧 イギリス（ロンドン）へのワーホリ
- 🇦🇺 オーストラリア（シドニー/メルボルン）へのワーホリ

---

## 🏗️ システムアーキテクチャ

```mermaid
graph TD
    A[main.py] -->|1. データ収集| B(scraper.py)
    B -->|API Request| C[Apify Instagram Hashtag Scraper]
    C -->|Instagram Data| B
    
    A -->|2. 解析・生成| D(analyzer.py)
    D -->|Post Text & Image| E[Google Gemini 2.0 Flash]
    E -->|Structured Data & Japanese Text| D
    
    A -->|3. 保存| F(database.py)
    F -->|Insert / Update| G[Supabase Database]
    
    H[Frontend Next.js] -->|API Call| I[/api/scrape]
    I -->|Execute with validation| A
    H -->|Direct Query| G
```

---

## 📁 ディレクトリ構成

```
scraping_system/
├── .env                      # 環境変数（APIキー）⚠️ Gitにコミットしない
├── main.py                   # メインスクリプト（司令塔）
├── scraper.py                # データ収集モジュール（Apify連携）
├── analyzer.py               # AI解析モジュール（Gemini連携）
├── database.py               # DB保存モジュール（Supabase連携）
├── schema.sql                # DBスキーマ定義
├── requirements.txt          # Python依存パッケージ
├── SYSTEM_ARCHITECTURE.md    # このファイル
├── SCRAPING_TARGETS.md       # スクレイピングターゲット設定
│
├── frontend/                 # Next.js フロントエンド
│   ├── app/
│   │   ├── admin/scraper/    # 管理画面
│   │   │   └── page.tsx      # スクレイパー管理UI
│   │   ├── api/scrape/       # APIルート（セキュリティ強化済み）
│   │   │   └── route.ts      # コマンドインジェクション対策済み
│   │   ├── layout.tsx
│   │   └── page.tsx
│   ├── pages/
│   │   └── api/              # Pages Router API（レガシー）
│   ├── public/
│   ├── styles/
│   ├── package.json
│   └── .env.local            # フロントエンド用環境変数
│
└── test_*.py                 # テストファイル
```

---

## 🐍 バックエンド（Python）

### ファイル構成と役割

| ファイル | 役割 | 連携API |
|---------|------|---------|
| **`main.py`** | 実行スクリプト。全体の処理順序を制御し、各モジュールを呼び出す | 全ファイル |
| **`scraper.py`** | 収集モジュール。Apify Hashtag Scraperを呼び出し、不要なデータをフィルタリング | **Apify API** |
| **`analyzer.py`** | 解析モジュール。Gemini Vision APIを呼び出し、テキスト+画像を解析して構造化 | **Google Gemini API** |
| **`database.py`** | 保存モジュール。Supabaseクライアントを操作し、データの整合性を保ちながら保存 | **Supabase** |
| **`.env`** | 設定ファイル。各APIキーを安全に管理 | なし (各モジュールが読み込み) |

### CLI引数

```bash
python main.py --country Toronto --days 14 --limit 10 --no-skip-duplicates
```

| 引数 | デフォルト | 説明 |
|------|-----------|------|
| `--country` | Toronto | ターゲット国（Toronto, Thailand, Philippines, UK, Australia） |
| `--days` | 14 | 何日前までの投稿を取得するか |
| `--limit` | 10 | 処理する最大投稿数 |
| `--no-skip-duplicates` | False | 重複フィルターを無効化 |

### カテゴリ優先順位

```
Job 💼 > House 🏠 > Event 🎉 > Ignore 🚫
```

求人情報が最も優先度が高く、無関係な投稿は最後になります。

---

## 🌐 フロントエンド（Next.js）

### 技術スタック

| パッケージ | バージョン | 用途 |
|-----------|-----------|------|
| Next.js | 16.1.6 | Reactフレームワーク（App Router） |
| React | 19.2.3 | UIライブラリ |
| @supabase/supabase-js | 2.95.3 | Supabaseクライアント |
| TypeScript | 5.x | 型安全な開発 |

### 主要ページ

| パス | 説明 |
|------|------|
| `/admin/scraper` | 管理画面：スクレイピング実行・結果確認・削除機能 |
| `/api/scrape` | APIエンドポイント：Pythonスクレイパーを起動 |

### 管理画面の機能

1. **スクレイピング実行**: 国・日数・件数を指定して実行
2. **結果一覧表示**: Supabaseから取得した投稿を表示
3. **選択削除**: チェックボックスで選択した投稿を削除
4. **全データ削除**: 確認後に全投稿を削除
5. **ログ表示**: 実行ログとサマリーを表示

### セキュリティ対策（2026-02-08 追加）

| 対策 | 実装内容 |
|------|---------|
| **コマンドインジェクション防止** | country入力をホワイトリスト検証 |
| **入力値バリデーション** | days/limit を数値範囲でバリデート |
| **許可された国のみ** | Toronto, Thailand, Philippines, UK, Australia のみ許可 |

---

## 🗄️ データベース（Supabase）

### `posts` テーブル

```sql
CREATE TABLE public.posts (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    instagram_shortcode TEXT NOT NULL UNIQUE,  -- 重複チェックキー
    status TEXT DEFAULT 'pending',              -- pending/published
    category TEXT,                              -- Job/House/Event/Ignore
    original_url TEXT,                          -- Instagram投稿URL
    posted_at TIMESTAMP WITH TIME ZONE,         -- 投稿日時
    author TEXT,                                -- Instagramユーザー名
    content TEXT,                               -- AI生成の日本語説明文
    details JSONB,                              -- 詳細データ
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### `details` JSONBカラムの構造

カテゴリによって含まれるフィールドが異なります：

```json
// Job の場合
{
  "rewritten_text": "日本語の説明文",
  "job_title": "Server",
  "shop_name": "KINKA IZAKAYA",
  "location": "Downtown Toronto",
  "instagram_shortcode": "xxx",
  "original_url": "https://...",
  "posted_at": "2026-02-01T10:00:00Z",
  "author": "kinka_izakaya"
}

// House の場合
{
  "rewritten_text": "日本語の説明文",
  "rent_price": 800,
  "area": "North York"
}

// Event の場合
{
  "rewritten_text": "日本語の説明文",
  "event_name": "Japan Festival",
  "event_date": "2026-03-15",
  "event_place": "Downtown Toronto"
}
```

### Row Level Security (RLS)

- **読み取り**: 匿名ユーザー（anon）に許可
- **書き込み**: 匿名ユーザー（anon）に許可（内部ツールのため）

⚠️ **推奨事項**: 本番環境では service_role キーでのみ書き込み可能にすることを推奨

---

## 🔑 環境変数

### ルートディレクトリ `.env`

```env
APIFY_TOKEN=apify_api_xxxxx
GEMINI_API_KEY=AIzaSyxxxxx
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_KEY=eyJhbGciOixxxx
```

### フロントエンド `/frontend/.env.local`

```env
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOixxxx
```

⚠️ **重要**: `.env` ファイルは `.gitignore` に含まれており、Gitにコミットされません。

---

## 🔧 外部サービス・API

### ① Apify (Instagram Hashtag Scraper)

- **Actor ID**: `apify~instagram-hashtag-scraper`
- **役割**: ハッシュタグ検索でInstagram投稿をJSON形式で返却
- **特徴**: 
  - ハッシュタグベースの検索で多様なソースから情報取得
  - Residentialプロキシ使用でブロック回避
  - 投稿テキスト、画像URL、shortcode、timestamp等を取得

### ② Google Gemini 2.0 Flash

- **モデル**: `gemini-2.0-flash`
- **役割**: 投稿の分類（Job/House/Event/Ignore）と日本語説明文の生成
- **Vision機能**: 画像内のテキストも解析可能（求人画像に多い）
- **レート制限**: Free Tier は約15 RPM → 20秒の待機時間を設定

### ③ Supabase

- **役割**: 解析済みデータの蓄積・管理
- **重複チェック**: `instagram_shortcode` をキーにしてUpsert処理

---

## 🔄 処理フロー詳細

```
1. Apify Instagram Hashtag Scraperでハッシュタグから投稿を取得
   ├── 最大5ハッシュタグを検索
   └── 各ハッシュタグから最大50件取得
           ↓
2. 日付フィルター（14日以内のみ）
           ↓
3. 重複フィルター（DB既存のshortcodeをスキップ）
           ↓
4. Gemini Vision APIでカテゴリ分類
   ├── 投稿テキスト解析
   └── 画像内テキスト解析（Vision）
           ↓
5. 優先順位でソート（Job > House > Event > Ignore）
           ↓
6. Supabaseに保存（Upsert）
```

---

## 🛡️ セキュリティ

### 実装済みセキュリティ対策

| 項目 | 対策 |
|------|------|
| **APIキー管理** | `.env`ファイルで管理、`.gitignore`でコミット防止 |
| **コマンドインジェクション** | ホワイトリストによる入力検証 |
| **入力バリデーション** | 数値の範囲チェック（days: 1-365, limit: 1-50） |

### 推奨事項（未実装）

| 項目 | 推奨内容 |
|------|---------|
| **管理画面認証** | `/admin/scraper` に認証機能を追加 |
| **RLS強化** | service_role キーのみで書き込み可能に |
| **レート制限** | API呼び出しの制限を実装 |

---

## 🛠️ 開発・運用コマンド

### バックエンド

```bash
# 依存パッケージインストール
pip install -r requirements.txt

# スクレイピング実行（トロント、14日、10件）
python main.py --country Toronto --days 14 --limit 10

# テスト実行
python test_analyzer.py
python test_supabase.py
```

### フロントエンド

```bash
cd frontend

# 依存パッケージインストール
npm install

# 開発サーバー起動
npm run dev

# 本番ビルド
npm run build
npm start
```

---

## 📚 関連ドキュメント

- [SCRAPING_TARGETS.md](./SCRAPING_TARGETS.md) - 国別スクレイピングターゲット設定
- [schema.sql](./schema.sql) - データベーススキーマ

---

## 📝 更新履歴

| 日付 | 内容 |
|------|------|
| 2026-02-08 | Apify Instagram Hashtag Scraper に移行 |
| 2026-02-08 | セキュリティ強化（コマンドインジェクション対策） |
| 2026-02-08 | デバッグコード削除、本番用に整備 |
| 2026-02-08 | システム仕様書をv2.0に更新 |
| 2026-02-08 | Gemini Vision（画像解析）対応を追加 |
| 2026-02-07 | 投稿削除機能を実装 |
| 2026-02-03 | Supabase RLS設定を追加 |
